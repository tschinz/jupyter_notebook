{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Scikit-Learn CheatSheet\n",
    "\n",
    "<img src=\"../sample_files/logos/scikit.svg\" width=\"200\" />\n",
    "\n",
    "Scikit-learn is an open source Python library that implements a range of machine learning, preprocessing, cross-validation and visualization algorithms using a unified interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, :2], iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Your data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "[[0.83253829 0.50398518 0.0931338  0.59153924 0.2563762 ]\n",
      " [0.09056077 0.42845796 0.65820855 0.14151847 0.86606923]\n",
      " [0.57335524 0.31312506 0.16328355 0.01007058 0.3900431 ]\n",
      " [0.85653543 0.20389465 0.22201192 0.70745912 0.46868355]\n",
      " [0.45783324 0.57638144 0.07202692 0.01713034 0.54638836]\n",
      " [0.89436925 0.65312998 0.28299846 0.58465384 0.52071888]\n",
      " [0.61164555 0.00313316 0.28995923 0.4243056  0.9690657 ]\n",
      " [0.02782185 0.49096337 0.79774603 0.05676063 0.8814525 ]\n",
      " [0.15854603 0.71335871 0.1118313  0.52119414 0.02201662]\n",
      " [0.10825882 0.11629826 0.92338134 0.61426038 0.87361918]\n",
      " [0.52808764 0.47773672 0.97026496 0.0853796  0.92004588]]\n",
      "X = \n",
      "[[0.83253829 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.86606923]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.85653543 0.         0.         0.70745912 0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.89436925 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.9690657 ]\n",
      " [0.         0.         0.79774603 0.         0.8814525 ]\n",
      " [0.         0.71335871 0.         0.         0.        ]\n",
      " [0.         0.         0.92338134 0.         0.87361918]\n",
      " [0.         0.         0.97026496 0.         0.92004588]]\n",
      "y = \n",
      "['M' 'M' 'F' 'F' 'M' 'F' 'M' 'M' 'F' 'F' 'F']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((11,5))\n",
    "print(\"X = \\n{}\".format(X))\n",
    "y = np.array(['M','M','F','F','M','F','M','M','F','F','F'])\n",
    "X[X < 0.7] = 0\n",
    "print(\"X = \\n{}\".format(X))\n",
    "print(\"y = \\n{}\".format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized_X = \n",
      "[[-0.77405591 -0.37796447  1.9450897  -0.37796447  1.02199553]\n",
      " [-0.77405591 -0.37796447 -0.57371999 -0.37796447  1.1296252 ]\n",
      " [-0.77405591 -0.37796447 -0.57371999 -0.37796447  0.90348245]\n",
      " [-0.77405591 -0.37796447  1.49723022 -0.37796447  0.93725851]\n",
      " [-0.77405591  2.64575131 -0.57371999 -0.37796447 -0.99809042]\n",
      " [ 1.27903779 -0.37796447 -0.57371999  2.64575131 -0.99809042]\n",
      " [ 1.22151725 -0.37796447 -0.57371999 -0.37796447 -0.99809042]\n",
      " [ 1.3697245  -0.37796447 -0.57371999 -0.37796447 -0.99809042]]\n",
      "standardized_X_test = \n",
      "[[-0.77405591 -0.37796447 -0.57371999 -0.37796447 -0.99809042]\n",
      " [-0.77405591 -0.37796447  1.82337973 -0.37796447  0.92005938]\n",
      " [-0.77405591 -0.37796447 -0.57371999 -0.37796447 -0.99809042]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "standardized_X = scaler.transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "print(\"standardized_X = \\n{}\".format(standardized_X))\n",
    "print(\"standardized_X_test = \\n{}\".format(standardized_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_X = \n",
      "[[0.         0.         0.72563616 0.         0.6880786 ]\n",
      " [0.         0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         0.         1.        ]\n",
      " [0.         0.         0.67102496 0.         0.74143476]\n",
      " [0.         1.         0.         0.         0.        ]\n",
      " [0.77101197 0.         0.         0.63682065 0.        ]\n",
      " [1.         0.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.        ]]\n",
      "normalized_X_test = \n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.72640937 0.         0.68726227]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer().fit(X_train)\n",
    "normalized_X = scaler.transform(X_train)\n",
    "normalized_X_test = scaler.transform(X_test)\n",
    "print(\"normalized_X = \\n{}\".format(normalized_X))\n",
    "print(\"normalized_X_test = \\n{}\".format(normalized_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_X = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binary_X = binarizer.transform(X)\n",
    "print(\"binary_X = \\n{}\".format(binary_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1 1 0 0 1 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "print(\"y = {}\".format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86114765, 0.71335871, 0.97026496, 0.70745912, 0.92004588],\n",
       "       [0.86114765, 0.71335871, 0.8840055 , 0.70745912, 0.9690657 ],\n",
       "       [0.86114765, 0.71335871, 0.8840055 , 0.70745912, 0.86606923],\n",
       "       [0.86114765, 0.71335871, 0.79774603, 0.70745912, 0.8814525 ],\n",
       "       [0.86114765, 0.71335871, 0.8840055 , 0.70745912, 0.90915833],\n",
       "       [0.85653543, 0.71335871, 0.8840055 , 0.70745912, 0.90915833],\n",
       "       [0.83253829, 0.71335871, 0.8840055 , 0.70745912, 0.90915833],\n",
       "       [0.89436925, 0.71335871, 0.8840055 , 0.70745912, 0.90915833]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values=0, strategy='mean', axis=0)\n",
    "imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.83253829, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.48726258],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.71335871, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.50887462],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.65924588]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(5)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "gnb = GaussianNB(priors=None)\n",
      "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "# Support Vector Machines (SVM)\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "# KNN\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "print(\"lr = {}\".format(lr))\n",
    "print(\"svc = {}\".format(svc))\n",
    "print(\"gnb = {}\".format(gnb))\n",
    "print(\"knn = {}\".format(knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca = PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "k_means = KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=0, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "# K Means\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3, random_state=0)\n",
    "\n",
    "print(\"pca = {}\".format(pca))\n",
    "print(\"k_means = {}\".format(k_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "k_means = KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=0, tol=0.0001, verbose=0)\n",
      "pca_model = [[ 0.83964032 -0.32430267 -0.2963779  -0.00320279]\n",
      " [ 0.4570015   0.18976501  0.43334823  0.01575435]\n",
      " [ 0.38781435  0.20498165  0.38079836  0.00970049]\n",
      " [ 0.73982508 -0.22590889 -0.19076596 -0.00261282]\n",
      " [-0.2295792   0.74396939 -0.38293279  0.06603886]\n",
      " [-0.81145423 -0.30361687  0.04071397  0.42316041]\n",
      " [-0.67380539 -0.12542316  0.00514874 -0.24678523]\n",
      " [-0.70944243 -0.15946446  0.01006736 -0.26205327]]\n"
     ]
    }
   ],
   "source": [
    "# Supervised learning\n",
    "lr.fit(X, y)                             # Fit the model to the data\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "# Unsupervised Learning\n",
    "k_means.fit(X_train)                     # Fit the model to the data\n",
    "pca_model = pca.fit_transform(X_train)   # Fit to data, then transform it\n",
    "\n",
    "print(\"lr = {}\".format(lr))\n",
    "print(\"svc = {}\".format(svc))\n",
    "print(\"knn = {}\".format(knn))\n",
    "print(\"k_means = {}\".format(k_means))\n",
    "print(\"pca_model = {}\".format(pca_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc.predict y_pred = ['F' 'F']\n",
      "lr.predict y_pred = [0.52566384 0.26923913 0.52566384]\n",
      "knn.predict_proba y_pred = [[0.4 0.6]\n",
      " [0.4 0.6]\n",
      " [0.4 0.6]]\n",
      "k_means.predict y_pred = [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Supervised Estimators\n",
    "y_pred = svc.predict(np.random.random((2,5))) # Predict labels\n",
    "print(\"svc.predict y_pred = {}\".format(y_pred))\n",
    "y_pred = lr.predict(X_test)                   # Predict labels\n",
    "print(\"lr.predict y_pred = {}\".format(y_pred))\n",
    "y_pred = knn.predict_proba(X_test)            # Estimate probability of a label\n",
    "print(\"knn.predict_proba y_pred = {}\".format(y_pred))\n",
    "# Unsupervised Estimators\n",
    "y_pred = k_means.predict(X_test)              # Predict labels in clustering algos\n",
    "print(\"k_means.predict y_pred = {}\".format(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.50      0.50         2\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.33      0.33      0.33         3\n",
      "\n",
      "[[1 1]\n",
      " [1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zas/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:181: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score\n",
    "knn.score(X_test, y_test)                         # Estimator score method\n",
    "from sklearn.metrics import accuracy_score        # Metric scoring functions\n",
    "accuracy_score(y_test, y_pred)\n",
    "enc = LabelEncoder()\n",
    "y_test = enc.fit_transform(y_test)\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report # Precision, recall, f1-score and support\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true = [3, -0.5, 2]\n",
      "y_pred = [0 1 0]\n",
      "mean_absolute_error = 2.1666666666666665\n",
      "mean_squared_error = 0.6666666666666666\n",
      "r2_score = -1.3461538461538463\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [3, -0.5, 2]\n",
    "mean_absolute_error = mean_absolute_error(y_true, y_pred)\n",
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error = mean_squared_error(y_test, y_pred)\n",
    "# R² Score\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"y_true = {}\".format(y_true))\n",
    "print(\"y_pred = {}\".format(y_pred))\n",
    "print(\"mean_absolute_error = {}\".format(mean_absolute_error))\n",
    "print(\"mean_squared_error = {}\".format(mean_squared_error))\n",
    "print(\"r2_score = {}\".format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true = [3, -0.5, 2]\n",
      "y_pred = [0 1 0]\n",
      "adjusted_rand_score = 0.0\n",
      "homogeneity_score = 0.5793801642856952\n",
      "v_measure_score = 0.7336804366512111\n"
     ]
    }
   ],
   "source": [
    "# Adjusted Rand Index\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score = adjusted_rand_score(y_true, y_pred)\n",
    "# Homogeneity\n",
    "from sklearn.metrics import homogeneity_score\n",
    "homogeneity_score = homogeneity_score(y_true, y_pred)\n",
    "# V-measure\n",
    "from sklearn.metrics import v_measure_score\n",
    "v_measure_score = v_measure_score(y_true, y_pred)\n",
    "\n",
    "print(\"y_true = {}\".format(y_true))\n",
    "print(\"y_pred = {}\".format(y_pred))\n",
    "print(\"adjusted_rand_score = {}\".format(adjusted_rand_score))\n",
    "print(\"homogeneity_score = {}\".format(homogeneity_score))\n",
    "print(\"v_measure_score = {}\".format(v_measure_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5]\n",
      "[-269.65711954   -0.95080087]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zas/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "print(cross_val_score(knn, X_train, y_train, cv=4))\n",
    "print(cross_val_score(lr, X, y, cv=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zas/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "params = {\"n_neighbors\": np.arange(1,3),\n",
    "          \"metric\": [\"euclidean\", \"cityblock\"]}\n",
    "grid = GridSearchCV(estimator=knn,\n",
    "                    param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "params = {\"n_neighbors\": range(1,5),\n",
    "          \"weights\": [\"uniform\", \"distance\"]}\n",
    "rsearch = RandomizedSearchCV(estimator=knn,\n",
    "                             param_distributions=params,\n",
    "cv=4,\n",
    "n_iter=8,\n",
    "random_state=5)\n",
    "rsearch.fit(X_train, y_train)\n",
    "print(rsearch.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
